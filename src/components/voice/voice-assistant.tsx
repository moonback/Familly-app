import { useEffect, useRef, useState } from 'react';
import { Mic, Square } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { detectIntent, DetectedIntent } from '@/lib/gemini';
import { useVoiceAssistantSettings } from '@/context/voice-assistant-context';
import { toast } from '@/hooks/use-toast';

interface VoiceAssistantProps {
  onIntent: (intent: DetectedIntent) => void;
}

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionResultList {
  [index: number]: SpeechRecognitionResult;
  length: number;
}

interface SpeechRecognitionResult {
  [index: number]: SpeechRecognitionAlternative;
  isFinal: boolean;
  length: number;
}

interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  onresult: (event: SpeechRecognitionEvent) => void;
  onend: () => void;
  onstart: () => void;
  onerror: (event: SpeechRecognitionErrorEvent) => void;
  start: () => void;
  stop: () => void;
}

export const VoiceAssistant = ({ onIntent }: VoiceAssistantProps) => {
  const { enabled } = useVoiceAssistantSettings();
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const [listening, setListening] = useState(false);
  const [retryCount, setRetryCount] = useState(0);
  const MAX_RETRIES = 3;

  const speak = (text: string) => {
    console.log('ğŸ”Š SynthÃ¨se vocale:', text);
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'fr-FR';
    utterance.onstart = () => console.log('ğŸ¤ DÃ©but de la synthÃ¨se vocale');
    utterance.onend = () => console.log('ğŸ¤ Fin de la synthÃ¨se vocale');
    utterance.onerror = (error) => console.error('âŒ Erreur de synthÃ¨se vocale:', error);
    window.speechSynthesis.speak(utterance);
  };

  const handleError = (error: string, message: string) => {
    console.error('âŒ Erreur de reconnaissance vocale:', error, message);
    
    if (error === 'no-speech') {
      if (retryCount < MAX_RETRIES) {
        setRetryCount(prev => prev + 1);
        toast({
          title: "Je n'ai pas entendu de voix",
          description: "Veuillez parler plus fort ou vÃ©rifier votre microphone",
          variant: "destructive"
        });
        // RedÃ©marrer l'Ã©coute aprÃ¨s un court dÃ©lai
        setTimeout(() => {
          if (recognitionRef.current) {
            recognitionRef.current.start();
          }
        }, 1000);
      } else {
        setRetryCount(0);
        setListening(false);
        toast({
          title: "Trop de tentatives",
          description: "Je n'ai pas pu entendre votre voix. Veuillez rÃ©essayer.",
          variant: "destructive"
        });
      }
    } else {
      setListening(false);
      toast({
        title: "Erreur de reconnaissance vocale",
        description: "Une erreur est survenue. Veuillez rÃ©essayer.",
        variant: "destructive"
      });
    }
  };

  useEffect(() => {
    console.log('ğŸ”„ Initialisation de la reconnaissance vocale');
    const SpeechRecognition =
      (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      console.error('âŒ La reconnaissance vocale n\'est pas supportÃ©e par ce navigateur');
      toast({
        title: "Navigateur non supportÃ©",
        description: "Votre navigateur ne supporte pas la reconnaissance vocale",
        variant: "destructive"
      });
      return;
    }
    const recognition = new SpeechRecognition() as SpeechRecognition;
    recognition.lang = 'fr-FR';
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onstart = () => {
      console.log('ğŸ¤ DÃ©but de l\'Ã©coute');
      setListening(true);
      toast({
        title: "Ã‰coute en cours",
        description: "Je vous Ã©coute...",
      });
    };

    recognition.onend = () => {
      console.log('ğŸ¤ Fin de l\'Ã©coute');
      setListening(false);
    };

    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      handleError(event.error, event.message);
    };

    recognition.onresult = async (e: SpeechRecognitionEvent) => {
      const transcript = Array.from(e.results)
        .map((r) => r[0].transcript)
        .join(' ');
      console.log('ğŸ¤ Texte reconnu:', transcript);
      setRetryCount(0); // RÃ©initialiser le compteur en cas de succÃ¨s
      
      try {
        const intent = await detectIntent(transcript);
        console.log('ğŸ¯ Intention dÃ©tectÃ©e:', intent);
        onIntent(intent);
        
        // RÃ©pondre vocalement Ã  l'utilisateur
        if (intent.intent === 'complete_task' && intent.task) {
          speak(`J'ai marquÃ© la tÃ¢che "${intent.task}" comme terminÃ©e`);
        } else if (intent.intent === 'get_points') {
          speak('Je vais vÃ©rifier tes points');
        } else {
          speak("DÃ©solÃ©, je n'ai pas compris ta demande");
        }
      } catch (error) {
        console.error('âŒ Erreur lors de la dÃ©tection d\'intention:', error);
        speak("DÃ©solÃ©, j'ai rencontrÃ© une erreur");
      }
    };

    recognitionRef.current = recognition;
    console.log('âœ… Reconnaissance vocale initialisÃ©e');
  }, [onIntent]);

  const toggle = () => {
    if (!recognitionRef.current) {
      console.error('âŒ La reconnaissance vocale n\'est pas initialisÃ©e');
      return;
    }
    if (listening) {
      console.log('ğŸ›‘ ArrÃªt de l\'Ã©coute');
      recognitionRef.current.stop();
      setRetryCount(0);
    } else {
      console.log('â–¶ï¸ DÃ©marrage de l\'Ã©coute');
      setRetryCount(0);
      recognitionRef.current.start();
    }
  };

  if (!enabled) {
    console.log('ğŸ”‡ Assistant vocal dÃ©sactivÃ©');
    return null;
  }

  return (
    <Button variant="outline" size="icon" onClick={toggle} className="ml-2">
      {listening ? <Square className="h-4 w-4" /> : <Mic className="h-4 w-4" />}
    </Button>
  );
};
