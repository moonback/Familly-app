import { useEffect, useRef, useState } from 'react';
import { Mic, Square } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { detectIntent, DetectedIntent } from '@/lib/gemini';
import { useVoiceAssistantSettings } from '@/context/voice-assistant-context';
import { toast } from '@/hooks/use-toast';
import { supabase } from '@/lib/supabase';
import { useAuth } from '@/context/auth-context';

interface VoiceAssistantProps {
  onIntent: (intent: DetectedIntent) => void;
}

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionResultList {
  [index: number]: SpeechRecognitionResult;
  length: number;
}

interface SpeechRecognitionResult {
  [index: number]: SpeechRecognitionAlternative;
  isFinal: boolean;
  length: number;
}

interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  onresult: (event: SpeechRecognitionEvent) => void;
  onend: () => void;
  onstart: () => void;
  onerror: (event: SpeechRecognitionErrorEvent) => void;
  start: () => void;
  stop: () => void;
}

export const VoiceAssistant = ({ onIntent }: VoiceAssistantProps) => {
  const { enabled } = useVoiceAssistantSettings();
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const [listening, setListening] = useState(false);
  const [retryCount, setRetryCount] = useState(0);
  const MAX_RETRIES = 3;
  const [hasRequestedPermission, setHasRequestedPermission] = useState(false);
  const [isMicrophoneAvailable, setIsMicrophoneAvailable] = useState(false);
  const streamRef = useRef<MediaStream | null>(null);
  const { user } = useAuth();

  const speak = (text: string) => {
    console.log('üîä Synth√®se vocale:', text);
    
    // R√©cup√©rer les r√©glages vocaux
    const savedSettings = localStorage.getItem('voiceSettings');
    const voiceSettings = savedSettings ? JSON.parse(savedSettings) : {
      rate: 1.0,
      pitch: 1.0,
      volume: 1.0,
      isMuted: false,
      isListening: false,
      preset: 'default',
      transitionSound: true
    };

    // Si le mode silencieux est activ√©, ne pas parler
    if (voiceSettings.isMuted) {
      console.log('üîá Mode silencieux activ√©');
      return;
    }

    // Jouer l'effet sonore de transition si activ√©
    if (voiceSettings.transitionSound) {
      try {
        const transitionSound = new Audio('/sounds/transition.mp3');
        transitionSound.volume = voiceSettings.volume * 0.5;
        transitionSound.play();
      } catch (error) {
        console.log('‚ÑπÔ∏è Effet sonore de transition non disponible');
      }
    }

    const utterance = new SpeechSynthesisUtterance(text);
    
    // Configuration de la voix avec les r√©glages sauvegard√©s
    utterance.lang = 'fr-FR';
    utterance.rate = voiceSettings.rate;
    utterance.pitch = voiceSettings.pitch;
    utterance.volume = voiceSettings.volume;

    // S√©lection de la meilleure voix fran√ßaise disponible
    const voices = window.speechSynthesis.getVoices();
    const frenchVoices = voices.filter(voice => voice.lang.includes('fr'));
    if (frenchVoices.length > 0) {
      // Pr√©f√©rer une voix f√©minine si disponible
      const preferredVoice = frenchVoices.find(voice => voice.name.includes('female')) || frenchVoices[0];
      utterance.voice = preferredVoice;
    }

    // Gestion des √©v√©nements
    utterance.onstart = () => {
      console.log('üé§ D√©but de la synth√®se vocale');
      setListening(false); // Arr√™ter l'√©coute pendant la synth√®se
    };
    
    utterance.onend = () => {
      console.log('üé§ Fin de la synth√®se vocale');
      // Jouer l'effet sonore de fin si activ√©
      if (voiceSettings.transitionSound) {
        try {
          const endSound = new Audio('/sounds/end.mp3');
          endSound.volume = voiceSettings.volume * 0.3;
          endSound.play();
        } catch (error) {
          console.log('‚ÑπÔ∏è Effet sonore de fin non disponible');
        }
      }
      // Reprendre l'√©coute si le mode √©coute continue est activ√©
      if (recognitionRef.current && voiceSettings.isListening) {
        recognitionRef.current.start();
      }
    };
    
    utterance.onerror = (error) => {
      console.error('‚ùå Erreur de synth√®se vocale:', error);
      toast({
        title: "Erreur de synth√®se vocale",
        description: "Une erreur est survenue lors de la lecture de la r√©ponse.",
        variant: "destructive"
      });
    };

    // Ajouter des pauses naturelles aux points et virgules
    const processedText = text
      .replace(/\./g, '. ')
      .replace(/,/g, ', ')
      .replace(/!/g, '! ')
      .replace(/\?/g, '? ');

    utterance.text = processedText;

    // Arr√™ter toute synth√®se vocale en cours
    window.speechSynthesis.cancel();
    
    // D√©marrer la nouvelle synth√®se
    window.speechSynthesis.speak(utterance);
  };

  const checkMicrophoneAvailability = async () => {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioDevices = devices.filter(device => device.kind === 'audioinput');
      console.log('üé§ P√©riph√©riques audio disponibles:', audioDevices);
      return audioDevices.length > 0;
    } catch (error) {
      console.error('‚ùå Erreur lors de la v√©rification des p√©riph√©riques:', error);
      return false;
    }
  };

  const requestMicrophonePermission = async () => {
    try {
      console.log('üé§ Demande d\'acc√®s au microphone...');
      
      // V√©rifier d'abord si des microphones sont disponibles
      const hasMicrophone = await checkMicrophoneAvailability();
      if (!hasMicrophone) {
        toast({
          title: "Aucun microphone d√©tect√©",
          description: "Veuillez connecter un microphone et r√©essayer",
          variant: "destructive"
        });
        return false;
      }

      // Demander la permission
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      
      // Garder une r√©f√©rence au stream
      streamRef.current = stream;
      console.log('‚úÖ Permission microphone accord√©e');
      setHasRequestedPermission(true);
      setIsMicrophoneAvailable(true);
      return true;
    } catch (error) {
      console.error('‚ùå Erreur lors de la demande de permission:', error);
      setIsMicrophoneAvailable(false);
      toast({
        title: "Acc√®s au microphone refus√©",
        description: "Veuillez autoriser l'acc√®s au microphone dans les param√®tres de votre navigateur",
        variant: "destructive"
      });
      return false;
    }
  };

  const stopMicrophone = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
  };

  const handleError = (error: string, message: string) => {
    console.error('‚ùå Erreur de reconnaissance vocale:', error, message);
    
    if (error === 'audio-capture') {
      setIsMicrophoneAvailable(false);
      stopMicrophone();
      
      if (!hasRequestedPermission) {
        requestMicrophonePermission();
      } else {
        toast({
          title: "Probl√®me avec le microphone",
          description: "Veuillez v√©rifier que votre microphone est bien connect√© et autoris√©",
          variant: "destructive"
        });
      }
      setListening(false);
    } else if (error === 'no-speech') {
      if (retryCount < MAX_RETRIES) {
        setRetryCount(prev => prev + 1);
        toast({
          title: "Je n'ai pas entendu de voix",
          description: "Veuillez parler plus fort ou v√©rifier votre microphone",
          variant: "destructive"
        });
        setTimeout(() => {
          if (recognitionRef.current && isMicrophoneAvailable) {
            recognitionRef.current.start();
          }
        }, 1000);
      } else {
        setRetryCount(0);
        setListening(false);
        toast({
          title: "Trop de tentatives",
          description: "Je n'ai pas pu entendre votre voix. Veuillez r√©essayer.",
          variant: "destructive"
        });
      }
    } else {
      setListening(false);
      toast({
        title: "Erreur de reconnaissance vocale",
        description: "Une erreur est survenue. Veuillez r√©essayer.",
        variant: "destructive"
      });
    }
  };

  const getResponse = async (text: string) => {
    try {
      const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
      if (!apiKey) {
        console.error('‚ùå Cl√© API Gemini manquante');
        throw new Error('Cl√© API Gemini manquante');
      }

      // R√©cup√©rer le prompt personnalis√©
      const systemPrompt = localStorage.getItem('voiceAssistantPrompt') || `Tu es un assistant vocal familial nomm√© "FamilleIA". R√©ponds de mani√®re naturelle et conversationnelle en fran√ßais.`;

      // Remplacer les variables pr√©d√©finies
      const replacedPrompt = await replacePredefinedVariables(systemPrompt);

      console.log('üîÑ Appel de l\'API Gemini...');
      const response = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,
        {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            contents: [{
              parts: [{
                text: `${replacedPrompt}

Utilisateur: ${text}
Assistant:`
              }]
            }],
            generationConfig: {
              temperature: 0.7,
              topK: 40,
              topP: 0.95,
              maxOutputTokens: 1024,
            }
          })
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå R√©ponse API non-OK:', response.status, errorText);
        throw new Error(`Erreur API: ${response.status} - ${errorText}`);
      }

      const data = await response.json();
      console.log('‚úÖ R√©ponse API re√ßue:', data);
      
      const generatedText = data.candidates?.[0]?.content?.parts?.[0]?.text;
      if (!generatedText) {
        console.error('‚ùå Pas de texte g√©n√©r√© dans la r√©ponse:', data);
        return "D√©sol√©, je n'ai pas pu g√©n√©rer une r√©ponse.";
      }

      return generatedText;
    } catch (error) {
      console.error('‚ùå Erreur lors de la g√©n√©ration de r√©ponse:', error);
      return "D√©sol√©, j'ai rencontr√© une erreur lors de notre conversation.";
    }
  };

  // Fonction pour remplacer les variables pr√©d√©finies
  const replacePredefinedVariables = async (prompt: string): Promise<string> => {
    try {
      if (!user) return prompt;

      // R√©cup√©rer les donn√©es des enfants
      const { data: childrenData } = await supabase
        .from('children')
        .select('*')
        .eq('user_id', user.id);

      // R√©cup√©rer les t√¢ches
      const { data: tasksData } = await supabase
        .from('child_tasks')
        .select(`
          *,
          children (
            name
          )
        `)
        .eq('user_id', user.id);

      // R√©cup√©rer les r√©compenses
      const { data: rewardsData } = await supabase
        .from('rewards')
        .select('*')
        .eq('user_id', user.id);

      // R√©cup√©rer les r√®gles
      const { data: rulesData } = await supabase
        .from('rules')
        .select('*')
        .eq('user_id', user.id);

      // R√©cup√©rer l'√©nigme du jour
      const { data: riddleData } = await supabase
        .from('daily_riddles')
        .select('*')
        .eq('user_id', user.id)
        .order('created_at', { ascending: false })
        .limit(1);

      // R√©cup√©rer les sanctions
      const { data: sanctionsData } = await supabase
        .from('penalties')
        .select('*')
        .eq('user_id', user.id)
        .eq('is_active', true);

      // Calculer les points totaux
      const totalPoints = childrenData?.reduce((sum, child) => sum + (child.points || 0), 0) || 0;

      // Formater les t√¢ches
      const tasksInProgress = tasksData?.filter(t => !t.is_completed)
        .map(t => `${t.children.name}: ${t.name}`)
        .join(', ') || 'Aucune t√¢che en cours';
      
      const tasksCompleted = tasksData?.filter(t => t.is_completed)
        .map(t => `${t.children.name}: ${t.name}`)
        .join(', ') || 'Aucune t√¢che termin√©e';

      // Formater les r√©compenses
      const availableRewards = rewardsData?.filter(r => r.is_available)
        .map(r => r.name)
        .join(', ') || 'Aucune r√©compense disponible';

      // Formater les sanctions
      const activeSanctions = sanctionsData?.map(s => s.description)
        .join(', ') || 'Aucune sanction active';

      // Remplacer les variables
      let processedPrompt = prompt
        .replace('{POINTS_TOTAUX}', totalPoints.toString())
        .replace('{TACHES_EN_COURS}', tasksInProgress)
        .replace('{TACHES_TERMINEES}', tasksCompleted)
        .replace('{RECOMPENSES_DISPONIBLES}', availableRewards)
        .replace('{ENIGME_DU_JOUR}', riddleData?.[0]?.question || 'Aucune √©nigme disponible')
        .replace('{SANCTIONS_ACTIVES}', activeSanctions);

      // Remplacer les variables avec param√®tres
      processedPrompt = processedPrompt.replace(/{POINTS_ENFANT\((.*?)\)}/g, (_, childName) => {
        const child = childrenData?.find(c => c.name.toLowerCase() === childName.toLowerCase());
        return child ? child.points.toString() : '0';
      });

      processedPrompt = processedPrompt.replace(/{REGLE_SPECIFIQUE\((.*?)\)}/g, (_, ruleName) => {
        const rule = rulesData?.find(r => r.name.toLowerCase() === ruleName.toLowerCase());
        return rule ? rule.description : 'R√®gle non trouv√©e';
      });

      // Si {POINTS_ENFANT} est utilis√© sans param√®tre, utiliser le premier enfant
      if (processedPrompt.includes('{POINTS_ENFANT}')) {
        const firstChild = childrenData?.[0];
        processedPrompt = processedPrompt.replace('{POINTS_ENFANT}', firstChild ? firstChild.points.toString() : '0');
      }

      return processedPrompt;
    } catch (error) {
      console.error('‚ùå Erreur lors du remplacement des variables:', error);
      return prompt;
    }
  };

  useEffect(() => {
    console.log('üîÑ Initialisation de la reconnaissance vocale');
    const SpeechRecognition =
      (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      console.error('‚ùå La reconnaissance vocale n\'est pas support√©e par ce navigateur');
      toast({
        title: "Navigateur non support√©",
        description: "Votre navigateur ne supporte pas la reconnaissance vocale",
        variant: "destructive"
      });
      return;
    }
    const recognition = new SpeechRecognition() as SpeechRecognition;
    recognition.lang = 'fr-FR';
    recognition.interimResults = false;
    recognition.continuous = false;

    recognition.onstart = () => {
      console.log('üé§ D√©but de l\'√©coute');
      setListening(true);
      toast({
        title: "√âcoute en cours",
        description: "Je vous √©coute...",
      });
    };

    recognition.onend = () => {
      console.log('üé§ Fin de l\'√©coute');
      setListening(false);
    };

    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      handleError(event.error, event.message);
    };

    recognition.onresult = async (e: SpeechRecognitionEvent) => {
      const transcript = Array.from(e.results)
        .map((r) => r[0].transcript)
        .join(' ');
      console.log('üé§ Texte reconnu:', transcript);
      setRetryCount(0);

      // Obtenir une r√©ponse conversationnelle
      const response = await getResponse(transcript);
      speak(response);
    };

    recognitionRef.current = recognition;
    console.log('‚úÖ Reconnaissance vocale initialis√©e');

    // Nettoyage lors du d√©montage du composant
    return () => {
      stopMicrophone();
    };
  }, []);

  const toggle = async () => {
    if (!recognitionRef.current) {
      console.error('‚ùå La reconnaissance vocale n\'est pas initialis√©e');
      return;
    }

    if (!hasRequestedPermission || !isMicrophoneAvailable) {
      const permissionGranted = await requestMicrophonePermission();
      if (!permissionGranted) return;
    }

    if (listening) {
      console.log('üõë Arr√™t de l\'√©coute');
      recognitionRef.current.stop();
      setRetryCount(0);
    } else {
      console.log('‚ñ∂Ô∏è D√©marrage de l\'√©coute');
      setRetryCount(0);
      recognitionRef.current.start();
    }
  };

  if (!enabled) {
    console.log('üîá Assistant vocal d√©sactiv√©');
    return null;
  }

  return (
    <Button variant="outline" size="icon" onClick={toggle} className="ml-2">
      {listening ? <Square className="h-4 w-4" /> : <Mic className="h-4 w-4" />}
    </Button>
  );
};
